{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwRUkA1GMfsI"
   },
   "source": [
    " # Evaluation of machine translation (MT) of large language modes (LLMs) on Chichewa\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B-mSSNRNBV4"
   },
   "source": [
    "**Project**: Chichewa NLP Project    |        **Date**: October 20, 2023.\n",
    "\n",
    "**Background**\n",
    "\n",
    "With the recent advancements in natural language processing, large language models (LLMs) like ChatGPT have emerged. These LLMs have demonstrated impressive performance in various natural language processing (NLP) tasks, such as machine translation (MT), text generation, sentence classification, and more. As these LLMs achieve state-of-the-art (SOTA) performance for high-resource languages such as English, Chinese, German, and French, attention has now shifted towards advancing NLP in low-resource languages. This shift is necessitated by the fact that the majority of the over 7,000 languages are considered low-resource due to their limited online text data.\n",
    "\n",
    "In this study, we conduct machine translation (MT) evaluations for Large Language Models (LLMs) and commonly used translation platforms, including Google Translate, Bing Microsoft Translator, ChatGPT, and NLLB, specifically focusing on Chichewa. We utilize two datasets for this evaluation.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "* Perform machine translation (MT) evaluation on Chichewa using two distinct benchmark datasets.\n",
    "* Compare the performance of Google Translate, Bing Microsoft Translator, ChatGPT, and NLLB on Chichewa using both datasets.\n",
    "* Introduce a new, high-quality machine translation benchmark dataset named `chichewa_nlp`.\n",
    "\n",
    "**Datasets**\n",
    "\n",
    "We use two datasets for this task:\n",
    "* [FLORES-200 ](https://github.com/facebookresearch/flores/blob/main/flores200/README.md): This dataset comprises translations from 842 distinct web articles, totaling 3,001 sentences. For Chichewa, we specifically employ the parallel devtest split `nya_Latn.devtest`, and for English, we use `eng_Latn.devtest`, which consists of 1,012 sentences.\n",
    "\n",
    "* **Chichewa NLP Benchmark Dataset for MT** `chichewa_nlp`: We introduce a novel benchmark dataset for Chichewa machine translation named `chichewa_nlp.`. This dataset is human-annotated and consists of 809 parallel data pairs, translating from English to Chichewa. The data is sourced from various text types, including news articles, WhatsApp posts, online translation datasets, political texts, and public health data.\n",
    "\n",
    "\n",
    "**LLMs and Translation Platforms**\n",
    "\n",
    "[Google Translate API](https://www.google.com/aclk?sa=l&ai=DChcSEwiviraSvP-BAxVkOwYAHWuOAesYABAAGgJ3cw&gclid=Cj0KCQjwhL6pBhDjARIsAGx8D5_eDZ-HCtFRBn4hijfoC5zZT0BHk_z0sL0Z-ILsMqsgevJcvh_GoIgaAtgIEALw_wcB&sig=AOD64_3Zp9mMPw30Trz91C1msIVI1JJ1Yg&q&adurl&ved=2ahUKEwi-7K6SvP-BAxWh0wIHHd8QBPAQ0Qx6BAgIEAE): Utilizing Google's neural machine translation technology, the Google Translate API enables instant text translation into more than one hundred languages, similar to the Google Translate service used in web and mobile applications.\n",
    "\n",
    "[Microsoft (MS) Azure](https://azure.microsoft.com/en-us/free/search/?ef_id=_k_Cj0KCQjwhL6pBhDjARIsAGx8D5_WBwjXDtl54jndhnypDnQ02rUhHIee46ULhIqC0wQOhrZsdt68v2MaArrJEALw_wcB_k_&OCID=AIDcmm4z26duq7_SEM__k_Cj0KCQjwhL6pBhDjARIsAGx8D5_WBwjXDtl54jndhnypDnQ02rUhHIee46ULhIqC0wQOhrZsdt68v2MaArrJEALw_wcB_k_&gclid=Cj0KCQjwhL6pBhDjARIsAGx8D5_WBwjXDtl54jndhnypDnQ02rUhHIee46ULhIqC0wQOhrZsdt68v2MaArrJEALw_wcB): Similar to the Google Translate API, Microsoft (MS) Azure supports text translation in over a hundred languages and can be accessed as Bing Translator for web and mobile applications.\n",
    "\n",
    "[OpenAI's GPT](https://platform.openai.com/docs/guides/gpt): The generative pre-trained transformer (GPT) powers the popular ChatGPT chatbot, known for generating human-like text. These GPT models are accessible through the OpenAI API. For this project, we leverage the latest GPT model, `gpt-3.5-turbo.`\n",
    "\n",
    "[NLLB ](https://arxiv.org/abs/2207.04672):  Introduced in the paper titled \"No Language Left Behind: Scaling Human-Centered Machine Translation\" by Meta AI in 2022, NLLB is a multilingual LLM capable of translating over 200 languages, including low-resource languages like Chichewa.\n",
    "**Evaluation**\n",
    "\n",
    "We use [SacreBLEU](http://aclweb.org/anthology/W18-6319) to compute [BLEU](https://cloud.google.com/translate/automl/docs/evaluate#:~:text=BLEU%20(BiLingual%20Evaluation%20Understudy)%20is,of%20high%20quality%20reference%20translations.) scores and [chrF](https://aclanthology.org/W15-3049/) given the morphologically-rich nature of Chichewa.\n",
    "The translation outputs are also evalauated by native speakers to compare the translation qualities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xf_8yhiRX9Xm"
   },
   "outputs": [],
   "source": [
    "# important libralies\n",
    "!pip install --upgrade google-cloud-translate\n",
    "!pip install googletrans\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install sacrebleu\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install  datasets\n",
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]\n",
    "!pip install requests uuid\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQ3OO6yvC0TX"
   },
   "outputs": [],
   "source": [
    "# transformers\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import evaluate\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StQ0R4Y_Xtg9"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import html\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "import requests, uuid, json\n",
    "from six import text_type\n",
    "from google.cloud import translate\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from googletrans import Translator, LANGUAGES\n",
    "from IPython.display import Image, display\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GijUcGzzz4My"
   },
   "source": [
    "**Chichewa NLP data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxNwBpaSj3_J",
    "outputId": "8facd82d-99c0-4332-a30e-7c841fa98ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the number of chichewa senteces in chichewa nlp data set: 809\n",
      " the number of english senteces in chichewa nlp data set: 809\n"
     ]
    }
   ],
   "source": [
    "# ensure the path is correct\n",
    "data_en_chichewa=pd.read_csv('/content/chichewa_en_nlp.csv',index_col=None)# load csv data\n",
    "data_ny_chichewa=pd.read_csv('/content/chichewa_ny_nlp.csv', index_col=None)\n",
    "chichewa_en=data_en_chichewa['0'].tolist() # convert pd.series into list\n",
    "chichewa_ny=data_ny_chichewa['0'].tolist()\n",
    "print(f' the number of chichewa senteces in chichewa nlp data set: {len(chichewa_en)}')\n",
    "print(f' the number of english senteces in chichewa nlp data set: {len(chichewa_ny)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1AwRS_Vzjs4"
   },
   "source": [
    "**Flores data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12Gv9-HkEgDt",
    "outputId": "b113eb00-55eb-4aa2-b7e0-20d4c150dda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the number of chichewa senteces in flores data set: 1012\n",
      " the number of english senteces in flores data set: 1012\n"
     ]
    }
   ],
   "source": [
    "# ensure the path is correct\n",
    "data_en_flores='/content/eng_Latn.devtest'\n",
    "data_ny_flores='/content/nya_Latn.devtest'\n",
    "with open(data_en_flores, \"r\") as f:\n",
    "  files = f.read()\n",
    "with open(data_ny_flores, \"r\") as f:\n",
    "  files1 = f.read()\n",
    "# convert text into list\n",
    "flores_en=[]\n",
    "sentences_en = [sentence.strip() for sentence in files.split('\\n') if sentence.strip()]\n",
    "\n",
    "flores_ny=[]\n",
    "sentences_ny = [sentence.strip() for sentence in files1.split('\\n') if sentence.strip()]\n",
    "\n",
    "# Print the list of sentences\n",
    "for sentence in sentences_en:\n",
    "  flores_en.append(sentence)\n",
    "for sentence in sentences_ny:\n",
    "  flores_ny.append(sentence)\n",
    "\n",
    "print(f' the number of chichewa senteces in flores data set: {len( flores_ny)}')\n",
    "print(f' the number of english senteces in flores data set: {len( flores_en)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eO0afCyuIC9e"
   },
   "source": [
    "# Google Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDqjMpdYHy2U"
   },
   "source": [
    "**Translating with Google translate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvwy5n_633cz"
   },
   "outputs": [],
   "source": [
    "en_ny_translations_google=[]\n",
    "ny_translations_google=[]\n",
    "\n",
    "# Set the environment variable to your Google Cloud credentials JSON file\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/sincere-pen-401719-37daac6dd7e0.json'\n",
    "\n",
    "# Initialize the translation client\n",
    "translate_client = translate.TranslationServiceClient()\n",
    "\n",
    "# Define your source and target languages\n",
    "source_language_code = \"EN\"  # English\n",
    "target_language_code = \"NY\"  # Chichewa\n",
    "\n",
    "# Translate the sentences\n",
    "for sentence in flores_en:\n",
    "    translation = translate_client.translate_text(\n",
    "        parent=f\"projects/sincere-pen-401719/locations/global\",\n",
    "        contents=[sentence],\n",
    "        source_language_code=source_language_code,\n",
    "        target_language_code=target_language_code,\n",
    "    )\n",
    "    translated_sentence = html.unescape(translation.translations[0].translated_text)\n",
    "    en_ny_translations_google.append((f'en: {sentence}',f'ny: {translated_sentence}'))\n",
    "    ny_translations_google.append(translated_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REaqeYMiINDg"
   },
   "source": [
    "**Automatic Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NI0SieEILuR"
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "\n",
    "bleu_result = bleu_metric.compute(predictions=ny_translations_google, references=chichewa_ny,tokenize='flores200')\n",
    "chrf_result = chrf_metric.compute(predictions=ny_translations_google, references=chichewa_ny)\n",
    "\n",
    "result = {\"bleu\": bleu_result[\"score\"], \"chrf\": chrf_result[\"score\"]}\n",
    "results = {k: round(v, 4) for k, v in result.items()}\n",
    "print(f'the BLEU score for english to chichewa Google translation: {results[\"bleu\"]}')\n",
    "print(f'the ChrF score for english to chichewa Google translation: {results[\"chrf\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR8ZN8ZeIAGr"
   },
   "source": [
    "**Saving Google translation results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ-ghNu_kjNs",
    "outputId": "51fb6d16-cbff-420e-b339-961d60c19725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to en_ny_translations_google.json\n"
     ]
    }
   ],
   "source": [
    "# Combine the sentences into a list of dictionaries\n",
    "en_ny_translations_google = [{\"en\": en, \"ny\": ny} for en, ny in zip(chichewa_en, ny_translations_google)]\n",
    "\n",
    "# Specify the filename for the JSON file\n",
    "filename = \"en_ny_translations_google.json\"\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(en_ny_translations_google, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON data has been written to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFMQf4UdIfya"
   },
   "source": [
    "# Bing Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlswhdZQ5b1j"
   },
   "source": [
    "**Setting the Azure account**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "location: westus\n",
    "\n",
    "key: 1bee95c1ea8147c9bd25d6d17b171***\n",
    "\n",
    "endpoint: https://api.cognitive.microsofttranslator.com/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjgNEf-W3ikE",
    "outputId": "e0cd321d-87e7-4253-dca4-cbde35d50364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters for chichewa nlp data: 98911\n",
      "Total number of characters for flores data: 131966\n"
     ]
    }
   ],
   "source": [
    "#---------------------\n",
    "# Limit of 2 million characters per hour\n",
    "# translate request is limited to 50,000 characters\n",
    "#-------------------------\n",
    "\n",
    "# Calculate the total number of characters in all text\n",
    "total_char_chichewa = sum(len(string) for string in chichewa_en)\n",
    "total_char_flores= sum(len(string) for string in flores_en)\n",
    "\n",
    "# Print the total\n",
    "print(\"Total number of characters for chichewa nlp data:\", total_char_chichewa)\n",
    "print(\"Total number of characters for flores data:\", total_char_flores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRLZeJ1J6LX4"
   },
   "source": [
    "**Create batches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5M19uuM6KQb",
    "outputId": "53ac93a2-ae6c-427f-c9c6-dd0b9b64ddf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Calculate the batch size\n",
    "batch_size = 300\n",
    "\n",
    "# Split the list into  batches\n",
    "batches = [chichewa_en[i:i + batch_size] for i in range(0, len(chichewa_en), batch_size)]\n",
    "print(len(batches ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD46GziW58JH"
   },
   "source": [
    "**Translation with MS Azure (Bing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtFYIP1NM-Id"
   },
   "outputs": [],
   "source": [
    "# en_ny_translations=[]\n",
    "ny_translations_batch3=[]\n",
    "\n",
    "\n",
    "body = [{'text': text} for text in batches[2] ]\n",
    "\n",
    "# Add your key and endpoint\n",
    "key = \"1bee95c1ea8147c9bd25d6d17b171***\"\n",
    "endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
    "location = \"westus\"\n",
    "\n",
    "path = '/translate'\n",
    "constructed_url = endpoint + path\n",
    "\n",
    "params = {\n",
    "    'api-version': '3.0',\n",
    "    'from': 'en',\n",
    "    'to': ['nya']\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': key,\n",
    "    'Ocp-Apim-Subscription-Region': location,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}\n",
    "request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "response = request.json()\n",
    "\n",
    "for i in range(len(batches[2])):\n",
    "    original_text =batches[2][i]\n",
    "    translation = response[i][\"translations\"][0][\"text\"]\n",
    "    # en_ny_translations.append((original_text, translation))\n",
    "    ny_translations_batch3.append( translation )\n",
    "\n",
    "\n",
    "with open('ny_translations_batch3.csv', 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write each element in the list as a separate row in the CSV file\n",
    "    for item in ny_translations_batch3:\n",
    "        csv_writer.writerow([item])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-TjJYk7zznT"
   },
   "source": [
    "**Putting translations together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_5aYsRssl5O"
   },
   "outputs": [],
   "source": [
    "file_paths = ['/content/ny_translations_batch1.csv','/content/ny_translations_batch2.csv','/content/ny_translations_batch3.csv']\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Read and concatenate the CSV files into one DataFrame\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path,header=None)\n",
    "    combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_data.to_csv('ny_translations_bing.csv', index=False)\n",
    "\n",
    "#read csv file\n",
    "files=pd.read_csv('/content/ny_translations_bing.csv')['0']\n",
    "ny_translations_bing=files.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCdM1oQc6Kmm"
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "\n",
    "bleu_result = bleu_metric.compute(predictions= ny_translations_bing, references=chichewa_ny,tokenize='flores200')\n",
    "chrf_result = chrf_metric.compute(predictions= ny_translations_bing, references=chichewa_ny)\n",
    "\n",
    "result = {\"bleu\": bleu_result[\"score\"], \"chrf\": chrf_result[\"score\"]}\n",
    "results = {k: round(v, 4) for k, v in result.items()}\n",
    "print(f'the BLEU score for english to chichewa Bing translation: {results[\"bleu\"]}')\n",
    "print(f'the ChrF score for english to chichewa Bing translation: {results[\"chrf\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnBfA0ae59Ei"
   },
   "source": [
    "**Saving Bing translate results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtupokvp58af",
    "outputId": "92542c20-0f4d-4f76-c67d-24633e8f2f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to en_ny_translations_bing_flores.json\n"
     ]
    }
   ],
   "source": [
    "# Combine the sentences into a list of dictionaries\n",
    "en_ny_translations_google = [{\"en\": en, \"ny\": ny} for en, ny in zip(flores_en, ny_translations_bing)]\n",
    "\n",
    "# Specify the filename for the JSON file\n",
    "filename = \"en_ny_translations_bing_flores.json\"\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(en_ny_translations_google, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON data has been written to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_y131Gp6W4s"
   },
   "source": [
    "**Saving Google translation results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nrkd1KzABeA"
   },
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nDqUoDK6idZ"
   },
   "source": [
    "**1. ChatGPT chatbot**\n",
    "\n",
    "We followed prompting approach described in [(Jiao et al., 2023)](https://arxiv.org/abs/2301.08745) using the translation prompt\n",
    "```\n",
    "Translate the following list of  sentences from  English to Chichewa (Nyanja).\n",
    "\n",
    "```\n",
    "\n",
    "Challenges:\n",
    "\n",
    "\n",
    "*   Hallucinations\n",
    "*   Mixing ids\n",
    "*   Missing translations\n",
    "*   Slow\n",
    "*  Inconsistincies in translations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl80C8qe_Qb2"
   },
   "source": [
    " **2. ChatGPT API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeLD443kA88G"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "api_key = 'sk-uH3UeJEQZRcPZ33bFOPbT3BlbkFJDTfLPKct59JtDEOl5***'\n",
    "openai.api_key = api_key\n",
    "\n",
    "def translate_sentences(input_list, src_lang, tgt_lang):\n",
    "  \"\"\"\n",
    "  Generate translation with chatgpt\n",
    "  input_list: source sentences\n",
    "  src_lang: source language\n",
    "  tgt_lang: target language\n",
    "\n",
    "  \"\"\"\n",
    "  translations = [] # store the list of translations\n",
    "\n",
    "  for sentence in input_list:\n",
    "      prompt = f\"Translate the following sentence from {src_lang} to {tgt_lang}:\\n {sentence}\" # translation prompt\n",
    "      prompt+=\"\\nTranslation:\"\n",
    "\n",
    "      # Call the ChatGPT API for  translations\n",
    "      response = openai.Completion.create(\n",
    "          engine=\"gpt-3.5-turbo-instruct\", # model family\n",
    "          prompt=prompt,\n",
    "          max_tokens=256,\n",
    "          temperature=0.3 # control out randomness\n",
    "      )\n",
    "\n",
    "      translation = response.choices[0].text.strip()\n",
    "      translations.append(translation)\n",
    "\n",
    "  return translations\n",
    "\n",
    "source_language = \"English\"\n",
    "target_language = \"Chichewa\"\n",
    "\n",
    "ny_translations = translate_sentences(flores_en, source_language, target_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5CMtPAeBDcx",
    "outputId": "aac36f82-d571-4320-b99f-a0096a41beba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ny_translations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKsSVyvIPiK7"
   },
   "source": [
    "**Automatic Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nnt-aJ9tPeMt",
    "outputId": "e7227652-2f31-4ba8-87de-7202cbe9fcb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sacrebleu:Tokenizer 'spm' has been changed to 'flores101', and may be removed in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the BLEU score for english to chichewa ChatGPT translation: 5.6283\n",
      "the ChrF score for english to chichewa ChatGPT translation: 30.4527\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "\n",
    "bleu_result = bleu_metric.compute(predictions=ny_translations, references=flores_ny,tokenize='flores200')\n",
    "chrf_result = chrf_metric.compute(predictions=ny_translations, references=flores_ny)\n",
    "\n",
    "result = {\"bleu\": bleu_result[\"score\"], \"chrf\": chrf_result[\"score\"]}\n",
    "results = {k: round(v, 4) for k, v in result.items()}\n",
    "print(f'the BLEU score for english to chichewa ChatGPT translation: {results[\"bleu\"]}')\n",
    "print(f'the ChrF score for english to chichewa ChatGPT translation: {results[\"chrf\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExUYp4wCPs7_"
   },
   "source": [
    "**Saving ChatGpt results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "togH-aTorCQr",
    "outputId": "8b93d537-e1c7-4ad8-afc3-c87b83bf9cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to en_ny_translations_ChatGPT_flores.json\n"
     ]
    }
   ],
   "source": [
    "# Combine the sentences into a list of dictionaries\n",
    "en_ny_translations_ChatGPT = [{\"en\": en, \"ny\": ny} for en, ny in zip(flores_en, ny_translations)]\n",
    "\n",
    "# Specify the filename for the JSON file\n",
    "filename = \"en_ny_translations_ChatGPT_flores.json\"\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(en_ny_translations_ChatGPT, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON data has been written to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omFODzwx7IgR"
   },
   "source": [
    "# NLLB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6y6HLZA-XEX"
   },
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdY2BL3d76Kc"
   },
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INGnmSJH-aOG"
   },
   "source": [
    "**NLLB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqlDIMr9769s"
   },
   "outputs": [],
   "source": [
    "def batch_translate_direct(input_list: list, src_lang: str, tgt_lang: str):\n",
    "  \"\"\"\n",
    "  Generate translations using NLLB\n",
    "  input_list: list source sentences\n",
    "  src_lang: source language code --> check NLLB list of lang codes\n",
    "  tgt_lang: target language code\n",
    "\n",
    "  Returns:\n",
    "  translation into target lang\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\",  src_lang=src_lang) # initialize tokenizer from NLLB\n",
    "  en_ny_translations=[]\n",
    "  ny_translations=[]\n",
    "  for line in input_list:\n",
    "    source = line\n",
    "    input=tokenizer(source, return_tensors=\"pt\") # tokenization\n",
    "    translated_tokens = model.generate(\n",
    "    **input, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang], max_length=1000) # generate translations\n",
    "    output=tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0] # decode the translated tokens\n",
    "    en_ny_translations.append((f'en: {source}',f'ny: {output}'))\n",
    "    ny_translations.append(output)\n",
    "\n",
    "  return  (en_ny_translations,ny_translations)\n",
    "en_ny_translations,ny_translations= batch_translate_direct(flores_en, src_lang=\"eng_Latn\", tgt_lang=\"nya_Latn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAaE8vvz-lgN"
   },
   "source": [
    "**Automatic Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0ASkmKYj640",
    "outputId": "19667ef8-f459-4e6d-bece-b57cd22419d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_ny_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOAS9Mcn90G0",
    "outputId": "8a057d6a-8088-4389-da4a-6ec270a4f46c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sacrebleu:Tokenizer 'spm' has been changed to 'flores101', and may be removed in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the BLEU score for english to chichewa NLLB translation: 15.8566\n",
      "the ChrF score for english to chichewa NLLB translation: 46.7084\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "\n",
    "bleu_result = bleu_metric.compute(predictions=ny_translations, references=flores_ny,tokenize='flores200')\n",
    "chrf_result = chrf_metric.compute(predictions=ny_translations, references=flores_ny)\n",
    "\n",
    "result = {\"bleu\": bleu_result[\"score\"], \"chrf\": chrf_result[\"score\"]}\n",
    "results = {k: round(v, 4) for k, v in result.items()}\n",
    "print(f'the BLEU score for english to chichewa NLLB translation: {results[\"bleu\"]}')\n",
    "print(f'the ChrF score for english to chichewa NLLB translation: {results[\"chrf\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1SV8uyl-iFN"
   },
   "source": [
    "**Saving NLLB translation results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VirIitvj9_F4",
    "outputId": "76de8c48-e07f-4314-d644-19bd9dae4cd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to en_ny_translations_NLLB_flores.json\n"
     ]
    }
   ],
   "source": [
    "# Combine the sentences into a list of dictionaries\n",
    "en_ny_translations_NLLB = [{\"en\": en, \"ny\": ny} for en, ny in zip(flores_en, ny_translations)]\n",
    "\n",
    "# Specify the filename for the JSON file\n",
    "filename = \"en_ny_translations_NLLB_flores.json\"\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(en_ny_translations_google, json_file, indent=4,ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON data has been written to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58R3r5_wsGzc"
   },
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2_bJl1pEViq"
   },
   "source": [
    "**Summary**\n",
    "\n",
    "We present the results in the **Table 1** below. All translation outputs are also saved in .json format and can be found in the results folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coALOs-bDJcR"
   },
   "source": [
    "| LLM | Chichewa NLP      |                   | FLORES-200                |                   |\n",
    "|-----------------------|------------------------|-------------------|-----------------------|-------------------|\n",
    "|                     | BLEU                   | ChrF              | BLEU                  | ChrF              |\n",
    "|-----------------------|------------------------|-------------------|-----------------------|-------------------|\n",
    "| Google Translate             | 17.1838                  | 49.8466            | 21.2157                 | 52.8351             |\n",
    "| MS Bing              | 15.0289                  | 48.7437             | 19.5783                 | 51.3756           |\n",
    "| ChatGPT(3.5)            | 4.5473                  | 30.8839             | 5.6283                 | 30.4527            |\n",
    "| NLLB          | 12.8351                 | 45.1251             | 15.8566                 | 46.7084             |\n",
    "\n",
    "\n",
    "\n",
    "Table 1: Comparison of performance of LLMs on Chichewa NLP and FLORES-200 datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUTvf81uowGZ"
   },
   "source": [
    "**Which LLM is faster?**\n",
    "\n",
    "1.   Google Translate -  ~2 minutes for flores and Chichewa nlp datasets.\n",
    "2.  MS Bing Translate -  ~1 second  minutes for 300 sentences.\n",
    "3. ChatGPT - ~ 12 mins for flores and ~ 16 mins for Chichewa nlp datasets.\n",
    "4. NLLB - ~ 2 hrs  for flores and ~ 1 hr 30 mins for Chichewa nlp datasets.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WVubPM4tG1Y"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Discussion and Conclusion**\n",
    "\n",
    "We present the results in **Table 1**. For the two languages under consideration, Google Translate achieved the highest BLEU scores of 17.18 and 21.21, with ChatGPT yielding significantly lower BLEU scores of 4.54 and 5.62 for the `chichewa_nlp` and `FLORES-200` datasets, respectively. In terms of translation speed, Google Translate and MS Bing proved to be the fastest, completing translations in under two minutes for each dataset. In contrast, ChatGPT and NLLB took up to 16 minutes and 2 hours for translation, respectively.\n",
    "\n",
    "This study introduced a new, high-quality, human-annotated MT benchmark dataset, `chichewa_nlp`. We also evaluated MT performance on Google Translate, Bing Microsoft Translator, ChatGPT, and NLLB. Google Translate outperformed other platforms in terms of BLEU scores for Chichewa. For our future work, we plan to expand our research to include additional languages and consider various model settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWv4tdnutLV2"
   },
   "source": [
    "**End ðŸ˜Š**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
