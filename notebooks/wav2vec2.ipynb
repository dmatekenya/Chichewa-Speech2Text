{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ecc01-cb40-4c23-84c6-b5081c791aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "import IPython.display as ipd\n",
    "import re\n",
    "import shutil\n",
    "from sphfile import SPHFile\n",
    "import json\n",
    "from transformers import Wav2Vec2FeatureExtractor,  Wav2Vec2CTCTokenizer, Wav2Vec2Processor, Wav2Vec2ForCTC, TrainingArguments, Trainer\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7525109a-3bb1-4486-9d43-848e7fcf48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e1cc27d-f200-4454-9319-fb915b05e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = Path.cwd().parents[0]\n",
    "DIR_DATA = CWD.joinpath('data', 'TIMIT')\n",
    "DIR_TRAIN = DIR_DATA.joinpath('TRAIN')\n",
    "DIR_TEST = DIR_DATA.joinpath('TEST')\n",
    "FILE_METADATA_TRAIN = DIR_DATA.joinpath('train_metadata.csv')\n",
    "FILE_METADATA_TEST = DIR_DATA.joinpath('test_metadata.csv')\n",
    "GENERATE_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94e7594a-3ac5-4fe9-a8fb-1d157327c267",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_strange_audio_format_to_wav(ind):\n",
    "    \"\"\"\n",
    "    Convert the audios from some strange non-wav to wav format.\n",
    "    \"\"\"\n",
    "    for file in ind.iterdir():\n",
    "        if file.suffix == \".WAV\" or file.suffix == \".wav\":\n",
    "            fname = file.parts[-1].split(\".\")[0]\n",
    "            outf = ind.joinpath(\"{}_wav.wav\".format(fname))\n",
    "            sph = SPHFile(str(file))\n",
    "            sph.write_wav(filename = str(outf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f15929e7-b2c8-4e3f-a43f-24041d0512d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_files_to_wav():\n",
    "    \"\"\"\n",
    "    Get through the train and test folder to convert the files.\n",
    "    \"\"\"\n",
    "    # colect all folders into a list\n",
    "    folders_to_process = []\n",
    "    for folder in DIR_TEST.iterdir():\n",
    "        if folder.is_dir():\n",
    "            for next_folder in folder.iterdir():\n",
    "                if next_folder.is_dir():\n",
    "                    folders_to_process.append(next_folder)\n",
    "                    \n",
    "    \n",
    "    for folder in DIR_TRAIN.iterdir():\n",
    "        if folder.is_dir():\n",
    "            for next_folder in folder.iterdir():\n",
    "                if next_folder.is_dir():\n",
    "                    folders_to_process.append(next_folder)\n",
    "\n",
    "    # process the folders\n",
    "    test = random.choice(folders_to_process)\n",
    "    WAVS = [i for i in test.iterdir() if i.suffix == \".WAV\"]\n",
    "    assert len(WAVS) > 0 \n",
    "    for folder in folders_to_process:\n",
    "        convert_strange_audio_format_to_wav(ind=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b9f034a3-2603-48d5-9df3-afc3e4084574",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_files_to_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44fcc152-00d2-41c4-888e-636a542bac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_strange_audio_format_to_wav(ind=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87446c33-474e-4079-8889-2ac82e017523",
   "metadata": {},
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6bf15-021f-4566-b4d5-8a90e06e14cb",
   "metadata": {},
   "source": [
    "## Define utility functions for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d3e7804-d5e6-4720-aeba-49a1cf61fc61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data_file(indir=None, output_file=None):\n",
    "    cnt = 1\n",
    "    data = []\n",
    "    for reg in indir.iterdir():\n",
    "        dia_reg = reg.parts[-1]\n",
    "        if reg.is_dir():\n",
    "            for user in reg.iterdir():\n",
    "                if user.is_dir():\n",
    "                    for file in user.iterdir():\n",
    "                        fname = file.parts[-1].split(\".\")[0]\n",
    "                        if \"wav\" in fname:\n",
    "                            cnt += 1\n",
    "                            TXT_file = user.joinpath(\"{}.TXT\".format(fname[:-4]))\n",
    "                            try:\n",
    "                                raw_txt = open(TXT_file, 'r').read()\n",
    "                                txt = \" \".join(raw_txt.split(\" \")[2:])\n",
    "                                txt = txt.replace(\"\\n\", \"\")\n",
    "                            except:\n",
    "                                print(raw_text)\n",
    "                                pass\n",
    "                            data_item = {'dialect_region': dia_reg, 'speaker_id': user.parts[-1],\n",
    "                                        'aud_file': file, 'trasnc_file': TXT_file, 'text': txt}\n",
    "                            data.append(data_item)\n",
    "    df = pd.DataFrame(data)\n",
    "    df['id'] = [i for i in range(1, len(df)+1)]\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16b30e5-a84a-4986-82b2-950c2ede4ac8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_special_charecters(txt):\n",
    "    chars_to_ignore_regex = '[\\,\\),\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "    lower_txt = txt.lower()\n",
    "\n",
    "    txt2 = re.sub(chars_to_ignore_regex, '', lower_txt)\n",
    "    return txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f80ef3d-1285-4e16-80cf-f1a261c2b614",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_files_to_wav(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            curr_fpath = Path(row['aud_file'])\n",
    "            fname = curr_fpath.parts[-1].split(\".\")[0]\n",
    "            new_fpath = curr_fpath.joinpath(curr_fpath.parents[0], \"{}_wav.wav\".format(fname))\n",
    "            sph = SPHFile(str(curr_fpath))\n",
    "            sph.write_wav(filename = str(new_fpath))\n",
    "            df.loc[idx, 'aud_file'] = str(new_fpath)\n",
    "        except:\n",
    "            print('Something went wrong')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29ecb14-310b-4c55-bf15-1a1ced7adbf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_weird_audio_format2wav():\n",
    "    df = convert_files_to_wav(df=df_test)\n",
    "    df.to_csv(FILE_METADATA_TEST, index=False)\n",
    "    \n",
    "    df = convert_files_to_wav(df=df_train)\n",
    "    df.to_csv(FILE_METADATA_TRAIN, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703f722c-0cf8-4fc3-872d-56e6a74105de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_all_chars(df, col):\n",
    "    text_vals = list(df[col].values)\n",
    "    all_text = \" \".join(text_vals)\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": vocab, \"all_text\": all_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f69bce-26ed-426d-bb0a-36006fc2f552",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_files_to_wav(ind):\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            curr_fpath = Path(row['aud_file'])\n",
    "            fname = curr_fpath.parts[-1].split(\".\")[0]\n",
    "            new_fpath = curr_fpath.joinpath(curr_fpath.parents[0], \"{}_wav.wav\".format(fname))\n",
    "            sph = SPHFile(str(curr_fpath))\n",
    "            sph.write_wav(filename = str(new_fpath))\n",
    "            df.loc[idx, 'aud_file'] = str(new_fpath)\n",
    "        except:\n",
    "            print('Something went wrong')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9a5ad-dbee-4b62-bfca-1d41a3fe573a",
   "metadata": {},
   "source": [
    "## Process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03725f30-3074-4d41-9122-2b858fdcee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_DATA:\n",
    "    df_test = generate_data_file(indir=DIR_TEST, output_file=FILE_METADATA_TEST)\n",
    "    df_train = generate_data_file(indir=DIR_TRAIN, output_file=FILE_METADATA_TRAIN)\n",
    "else:\n",
    "    df_test = pd.read_csv(FILE_METADATA_TEST)\n",
    "    df_train = pd.read_csv(FILE_METADATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4985de3a-2228-4b2d-9781-9cb1e2ad4467",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_random_elements(df, num_examples=10):\n",
    "    assert num_examples <= len(df), \"Can't pick more elements than there are in the dataset.\"\n",
    "    indices = df.index.values\n",
    "    picks = random.choices(indices, k=num_examples)\n",
    "    df = df.iloc[picks][['text']]\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "706945ba-5aa5-4bac-a918-534121fe4927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>Assume, for example, a situation where a farm has a packing shed and fields.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>It gave her a lewd, winking effect.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>He may try to phone us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>She had your dark suit in greasy wash water all year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3381</th>\n",
       "      <td>The wrinkled mouth laughed, revealing astonishingly strong, white, teeth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Tim takes Sheila to see movies twice a week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>Any organism that falters or misperceives the signals or weakens is done.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>The haunted house was a hit due to outstanding audio-visual effects.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>Valley Lodge yearly celebrates the first calf born.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(df=df_train, num_examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84aa9d0c-1f61-4101-9d64-373a0d2564c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text_no_quotes\"] = df_train.text.apply(lambda x: remove_special_charecters(x))\n",
    "df_test[\"text_no_quotes\"] = df_test.text.apply(lambda x: remove_special_charecters(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51f99f-2dd4-4575-a22f-39e87b041881",
   "metadata": {},
   "source": [
    "# Generate Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54009c04-41ca-4f2a-a642-f0f7447c3e7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_vocubalary(df_train, df_test, output_vocab_file):\n",
    "    res_train = extract_all_chars(df_train, \"text_no_quotes\")\n",
    "    res_test = extract_all_chars(df_test, \"text_no_quotes\")\n",
    "    \n",
    "    vocab_list = list(set(res_train[\"vocab\"]) | set(res_test[\"vocab\"]))\n",
    "    \n",
    "    vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "    vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "    del vocab_dict[\" \"]\n",
    "    \n",
    "    vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "    vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "    \n",
    "\n",
    "    with open(vocab_file, 'w') as file:\n",
    "        json.dump(vocab_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d2e0ecf-485b-4a04-8118-bed1a14f159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = DIR_DATA.joinpath('vocab.json')\n",
    "generate_vocubalary(df_train, df_test, output_vocab_file=vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f902e3-d557-436c-bebc-b76e5c23e79d",
   "metadata": {},
   "source": [
    "# Prepare Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5109a684-c8b0-4b50-9e11-0684e94c008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(str(vocab_file), unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n",
    "PROCESSOR = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51cb7534-db96-472d-b626-d045d4c3f779",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(row):\n",
    "    sample_rate, audio = wavfile.read(row['aud_file'])\n",
    "    \n",
    "    if sample_rate != 16000:\n",
    "        sample_rate = 16000\n",
    "\n",
    "    # batched output is \"un-batched\" to ensure mapping is correct\n",
    "    input_val = PROCESSOR(np.asarray(audio), sampling_rate=sample_rate).input_values[0]\n",
    "    \n",
    "    with PROCESSOR.as_target_processor():\n",
    "        processed_txt = PROCESSOR(row[\"text\"]).input_ids\n",
    "    \n",
    "    return input_val, processed_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a613896-c1f6-4c9c-bd38-e6a859d63842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['input_values'] = df_train.apply(lambda x: prepare_dataset(x)[0], axis=1)\n",
    "df_train['labels'] = df_train.apply(lambda x: prepare_dataset(x)[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5895472-e7cb-45ce-a804-d1dd573158bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Mean of empty slice.\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/feature_extraction_wav2vec2.py:98: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  normed_input_values = [(x - x.mean()) / np.sqrt(x.var() + 1e-7) for x in input_values]\n",
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "df_test['input_values'] = df_test.apply(lambda x: prepare_dataset(x)[0], axis=1)\n",
    "df_test['labels'] = df_test.apply(lambda x: prepare_dataset(x)[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05aa2f8e-90de-46d1-88c7-241b5c785769",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['input_values', 'labels']\n",
    "dataset_train = Dataset.from_pandas(df_train[cols_to_keep])\n",
    "dataset_test = Dataset.from_pandas(df_test[cols_to_keep])\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = dataset_train\n",
    "ds['test'] = dataset_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693be717-ff01-4b20-97d5-3ac47a4637cc",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85ce4d4c-481b-4387-ba67-0442bd355f05",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2cc642f-2f40-4a10-ac9a-21aefdfc8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=PROCESSOR, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59cb9fe9-38b3-42c5-95e8-b60670328f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a477904-83c6-46ce-9ee8-a10418f6ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9358f3d-4317-4a1a-8396-ca879edbf894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/transformers/configuration_utils.py:358: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.bias', 'project_q.weight', 'project_hid.weight', 'quantizer.weight_proj.weight', 'project_hid.bias', 'project_q.bias', 'quantizer.codevectors']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=PROCESSOR.tokenizer.pad_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58951b2f-3437-4051-8367-94dcce796aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1674: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2de9920b-ed3c-44fd-9136-3aebd9d5d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = CWD.joinpath('models', 'end_models') \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=model_output_dir,\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=8,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=1,\n",
    "  gradient_checkpointing=True, \n",
    "  save_steps=500,\n",
    "  eval_steps=500,\n",
    "  logging_steps=500,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=0.005,\n",
    "  warmup_steps=1000,\n",
    "  save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f631406-2e9b-40b7-b6db-e2b663053634",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    tokenizer=PROCESSOR.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89ebc745-801b-4078-af47-a35cf5834ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4620\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 578\n",
      "/Users/dmatekenya/opt/anaconda3/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [501/578 4:01:58 < 37:20, 0.03 it/s, Epoch 0.87/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1680\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w3/dfvgjkh10wz8t573m_c20xf00000gp/T/ipykernel_77084/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1495\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1497\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1498\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2285\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mobserved_num_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2448\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2449\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/w3/dfvgjkh10wz8t573m_c20xf00000gp/T/ipykernel_77084/1808653673.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlabel_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         batch = self.processor.pad(\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mPreTrainedTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mrefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mabove\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/feature_extraction_sequence_utils.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;31m# first_element might be an empty list/tuple in some edge cases so we grab the first non empty element.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb05aa2-7bee-401a-80c6-e80a497c1e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
